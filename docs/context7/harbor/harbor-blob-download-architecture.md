# Harbor Blob Download Architecture: Pulling Changes & Downloading Referenced Blobs (Context7 Summary)

This document dives deep into **Harbor's architecture and call stack for downloading blobs** that are referenced by pulled changes (artifacts/manifests). This is particularly relevant to DataForge's sync architecture where Parquet files (blobs) need to be downloaded when syncing changes from the server.

It builds on:

- `harbor-object-storage-architecture.md`

and provides detailed call stacks and implementation patterns for the critical "pull changes â†’ identify missing blobs â†’ download blobs" flow.

---

## 1. High-Level Architecture Pattern

### 1.1 The Problem

When pulling changes from Harbor (or any container registry), the client receives:

1. **Manifest** (metadata about the artifact).
2. **Blob references** (digests of blob layers that need to be downloaded).
3. **Missing blob list** (blobs the client doesn't have locally).

The client must:

- **Parse** the manifest to extract blob digests.
- **Check** which blobs are already present locally (deduplication).
- **Download** missing blobs from object storage.
- **Verify** blob integrity (SHA-256 digest).
- **Store** blobs in local storage.

### 1.2 The Solution: Manifest â†’ Blob References â†’ Download

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Pull Changes from Server                          â”‚
â”‚  GET /api/sync/pull?workspace_id=X&from_version=Y                   â”‚
â”‚  Response: {                                                         â”‚
â”‚    changes: [                                                        â”‚
â”‚      {entity_type: "artifact", action: "create", data: {...}},      â”‚
â”‚    ],                                                                â”‚
â”‚    missing_blobs: ["sha256:abc...", "sha256:def..."]                â”‚
â”‚  }                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ Parse manifest, extract blob digests
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Identify Missing Blobs                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FOR each blob digest in manifest:                           â”‚  â”‚
â”‚  â”‚    - Check if blob exists locally (by digest)                â”‚  â”‚
â”‚  â”‚    - IF not exists: Add to missing_blobs list                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ Download missing blobs
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Download Blobs from Object Storage                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FOR each missing blob:                                      â”‚  â”‚
â”‚  â”‚    - GET /v2/{name}/blobs/{digest}                          â”‚  â”‚
â”‚  â”‚    - Stream blob data                                        â”‚  â”‚
â”‚  â”‚    - Verify SHA-256 digest                                   â”‚  â”‚
â”‚  â”‚    - Store in local blob storage                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Harbor's Blob Download Architecture

### 2.1 Docker Distribution API

Harbor uses the **Docker Distribution API** (OCI specification) for blob downloads:

```
GET /v2/{name}/blobs/{digest}
```

Where:

- `{name}` = repository name (e.g., `project/app`).
- `{digest}` = SHA-256 digest of the blob (e.g., `sha256:a3f2b8c9...`).

### 2.2 Storage Driver Abstraction

Harbor's storage drivers handle blob retrieval transparently:

- **Filesystem Driver**: Reads from local disk.
- **S3 Driver**: Downloads from S3-compatible storage.
- **Azure Blob Driver**: Downloads from Azure Blob Storage.
- **GCS Driver**: Downloads from Google Cloud Storage.

All drivers implement the same interface:

```go
type Driver interface {
    // Read blob from storage
    Reader(ctx context.Context, path string, offset int64) (io.ReadCloser, error)

    // Stat blob (get metadata: size, digest)
    Stat(ctx context.Context, path string) (FileInfo, error)
}
```

---

## 3. Complete Call Stack: Pull Changes & Download Blobs

### 3.1 High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Pull Changes from Server                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  GET /api/sync/pull?workspace_id=X&from_version=Y            â”‚  â”‚
â”‚  â”‚  Response: {                                                  â”‚  â”‚
â”‚  â”‚    changes: [                                                 â”‚  â”‚
â”‚  â”‚      {                                                        â”‚  â”‚
â”‚  â”‚        entity_type: "artifact",                               â”‚  â”‚
â”‚  â”‚        entity_id: "...",                                      â”‚  â”‚
â”‚  â”‚        action: "create",                                      â”‚  â”‚
â”‚  â”‚        data: {                                                â”‚  â”‚
â”‚  â”‚          digest: "sha256:manifest-digest",                    â”‚  â”‚
â”‚  â”‚          manifest: {...}  // Full manifest JSON               â”‚  â”‚
â”‚  â”‚        }                                                      â”‚  â”‚
â”‚  â”‚      }                                                        â”‚  â”‚
â”‚  â”‚    ],                                                         â”‚  â”‚
â”‚  â”‚    missing_blobs: ["sha256:abc...", "sha256:def..."]         â”‚  â”‚
â”‚  â”‚  }                                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Parse manifest, extract blob digests
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Parse Manifest & Extract Blob References                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  const manifest = JSON.parse(change.data.manifest);          â”‚  â”‚
â”‚  â”‚  const blobDigests = [];                                     â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  // Extract config blob digest                               â”‚  â”‚
â”‚  â”‚  if (manifest.config) {                                      â”‚  â”‚
â”‚  â”‚    blobDigests.push(manifest.config.digest);                 â”‚  â”‚
â”‚  â”‚  }                                                            â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  // Extract layer blob digests                               â”‚  â”‚
â”‚  â”‚  if (manifest.layers) {                                      â”‚  â”‚
â”‚  â”‚    manifest.layers.forEach(layer => {                        â”‚  â”‚
â”‚  â”‚      blobDigests.push(layer.digest);                         â”‚  â”‚
â”‚  â”‚    });                                                        â”‚  â”‚
â”‚  â”‚  }                                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Check which blobs are missing locally
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Check Local Blob Storage                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  const missingBlobs = [];                                    â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  FOR each blobDigest in blobDigests:                         â”‚  â”‚
â”‚  â”‚    - Check if blob exists locally:                           â”‚  â”‚
â”‚  â”‚      SELECT 1 FROM blob_registry                             â”‚  â”‚
â”‚  â”‚      WHERE digest = ?                                        â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚    - IF not exists:                                          â”‚  â”‚
â”‚  â”‚        missingBlobs.push(blobDigest);                        â”‚  â”‚
â”‚  â”‚    - ELSE:                                                   â”‚  â”‚
â”‚  â”‚        Skip (blob already downloaded)                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Download missing blobs
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Download Missing Blobs                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FOR each missingBlob in missingBlobs:                       â”‚  â”‚
â”‚  â”‚    a. Request blob download                                  â”‚  â”‚
â”‚  â”‚    b. Stream blob data                                       â”‚  â”‚
â”‚  â”‚    c. Verify digest                                          â”‚  â”‚
â”‚  â”‚    d. Store in local storage                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Update metadata
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Update Local Metadata                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FOR each downloaded blob:                                   â”‚  â”‚
â”‚  â”‚    - INSERT INTO blob_registry (digest, size, path, ...)    â”‚  â”‚
â”‚  â”‚    - Link blob to artifact:                                  â”‚  â”‚
â”‚  â”‚      INSERT INTO artifact_blob_ref (artifact_id, blob_digest)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Detailed Call Stack: Downloading a Single Blob

### 4.1 Blob Download Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client: Request Blob Download                                      â”‚
â”‚  GET /v2/{name}/blobs/{digest}                                      â”‚
â”‚  Headers:                                                            â”‚
â”‚    Authorization: Bearer {token}                                    â”‚
â”‚    Range: bytes=0-1048575  (optional, for chunked download)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ Harbor Core API: Authentication
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Harbor Core API: Authentication & Authorization                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  - Validate JWT token / session                              â”‚  â”‚
â”‚  â”‚  - Check project permissions (pull access)                   â”‚  â”‚
â”‚  â”‚  - Check if project/repository is public                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Proxy to Docker Distribution Registry
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Docker Distribution: Resolve Blob Path                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  - Parse digest: sha256:a3f2b8c9...                          â”‚  â”‚
â”‚  â”‚  - Derive blob path:                                         â”‚  â”‚
â”‚  â”‚    blobs/sha256/a3/f2/a3f2b8c9...                            â”‚  â”‚
â”‚  â”‚  - Check if blob exists in storage                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Storage Driver: Open Blob Reader
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Storage Driver: Open Blob Reader                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Filesystem Driver:                                          â”‚  â”‚
â”‚  â”‚    - Open file: /var/lib/registry/blobs/sha256/a3/f2/...    â”‚  â”‚
â”‚  â”‚    - Return file reader (with seek support)                 â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  S3 Driver:                                                  â”‚  â”‚
â”‚  â”‚    - Generate presigned URL (if configured)                 â”‚  â”‚
â”‚  â”‚    - Or: s3.GetObject(bucket, key)                          â”‚  â”‚
â”‚  â”‚    - Return streaming reader                                â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  Azure Blob Driver:                                          â”‚  â”‚
â”‚  â”‚    - azure.GetBlob(container, blobName)                     â”‚  â”‚
â”‚  â”‚    - Return streaming reader                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Stream blob data to client
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Stream Blob Data to Client                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  - Read blob data in chunks (e.g., 64KB)                    â”‚  â”‚
â”‚  â”‚  - Stream to HTTP response                                   â”‚  â”‚
â”‚  â”‚  - Support Range requests (resume downloads)                 â”‚  â”‚
â”‚  â”‚  - Set Content-Type, Content-Length headers                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Client: Receive & Verify Blob
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Client: Receive & Verify Blob                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  - Stream blob data to temporary file                        â”‚  â”‚
â”‚  â”‚  - Compute SHA-256 digest while downloading                  â”‚  â”‚
â”‚  â”‚  - Verify digest matches expected digest                     â”‚  â”‚
â”‚  â”‚  - Move to final location:                                   â”‚  â”‚
â”‚  â”‚    blobs/sha256/a3/f2/a3f2b8c9...                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Manifest Parsing & Blob Reference Extraction

### 5.1 Docker/OCI Manifest Structure

```json
{
	"schemaVersion": 2,
	"mediaType": "application/vnd.docker.distribution.manifest.v2+json",
	"config": {
		"mediaType": "application/vnd.docker.container.image.v1+json",
		"size": 1500,
		"digest": "sha256:244718b7c845e40677786874f5e889f2c289292a67d34828a745782f21c9891a"
	},
	"layers": [
		{
			"mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",
			"size": 32000000,
			"digest": "sha256:4c4458b57c2187a4b03281b6524e65015799765819c578140e665c136a563c30"
		},
		{
			"mediaType": "application/vnd.docker.image.rootfs.diff.tar.gzip",
			"size": 15000000,
			"digest": "sha256:7b1c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c"
		}
	]
}
```

### 5.2 Extract Blob Digests from Manifest

```typescript
interface Manifest {
	schemaVersion: number;
	mediaType: string;
	config?: {
		mediaType: string;
		size: number;
		digest: string;
	};
	layers?: Array<{
		mediaType: string;
		size: number;
		digest: string;
	}>;
}

function extractBlobDigests(manifest: Manifest): string[] {
	const digests: string[] = [];

	// Extract config blob digest
	if (manifest.config?.digest) {
		digests.push(manifest.config.digest);
	}

	// Extract layer blob digests
	if (manifest.layers) {
		manifest.layers.forEach((layer) => {
			if (layer.digest) {
				digests.push(layer.digest);
			}
		});
	}

	return digests;
}

// Example usage
const manifest: Manifest = JSON.parse(change.data.manifest);
const blobDigests = extractBlobDigests(manifest);
// Result: [
//   "sha256:244718b7c845e40677786874f5e889f2c289292a67d34828a745782f21c9891a",
//   "sha256:4c4458b57c2187a4b03281b6524e65015799765819c578140e665c136a563c30",
//   "sha256:7b1c3d4e5f6a7b8c9d0e1f2a3b4c5d6e7f8a9b0c1d2e3f4a5b6c7d8e9f0a1b2c"
// ]
```

---

## 6. Blob Download Implementation

### 6.1 Check Local Blob Storage

```typescript
async function checkLocalBlobs(db: Database, blobDigests: string[]): Promise<string[]> {
	const missingBlobs: string[] = [];

	for (const digest of blobDigests) {
		// Check if blob exists locally
		const exists = await db.get('SELECT 1 FROM blob_registry WHERE digest = ?', [digest]);

		if (!exists) {
			missingBlobs.push(digest);
		}
	}

	return missingBlobs;
}
```

### 6.2 Download Blob with Verification

```typescript
import crypto from 'crypto';
import fs from 'fs';
import path from 'path';

async function downloadBlob(
	client: HttpClient,
	repositoryName: string,
	digest: string,
	localBlobPath: string
): Promise<void> {
	// Derive blob path from digest
	// sha256:a3f2b8c9... -> blobs/sha256/a3/f2/a3f2b8c9...
	const digestHash = digest.replace('sha256:', '');
	const blobPath = `blobs/sha256/${digestHash.slice(0, 2)}/${digestHash.slice(2, 4)}/${digestHash}`;

	// Ensure directory exists
	const blobDir = path.dirname(localBlobPath);
	await fs.promises.mkdir(blobDir, { recursive: true });

	// Request blob download
	const response = await client.get(`/v2/${repositoryName}/blobs/${digest}`, {
		responseType: 'stream' // Stream response for large files
	});

	// Create temporary file for download
	const tempPath = `${localBlobPath}.tmp`;
	const writeStream = fs.createWriteStream(tempPath);

	// Create SHA-256 hash for verification
	const hash = crypto.createHash('sha256');

	// Stream blob data to file and compute hash
	return new Promise((resolve, reject) => {
		response.data.on('data', (chunk: Buffer) => {
			writeStream.write(chunk);
			hash.update(chunk);
		});

		response.data.on('end', async () => {
			writeStream.end();

			// Verify digest
			const computedDigest = `sha256:${hash.digest('hex')}`;
			if (computedDigest !== digest) {
				// Delete corrupted blob
				await fs.promises.unlink(tempPath);
				reject(new Error(`Digest mismatch: expected ${digest}, got ${computedDigest}`));
				return;
			}

			// Move temporary file to final location (atomic)
			await fs.promises.rename(tempPath, localBlobPath);

			resolve();
		});

		response.data.on('error', (error: Error) => {
			writeStream.destroy();
			fs.promises.unlink(tempPath).catch(() => {});
			reject(error);
		});
	});
}
```

### 6.3 Batch Blob Download with Progress

```typescript
interface BlobDownloadProgress {
	digest: string;
	status: 'pending' | 'downloading' | 'completed' | 'failed';
	bytesDownloaded: number;
	totalBytes: number;
	error?: string;
}

async function downloadBlobs(
	client: HttpClient,
	repositoryName: string,
	missingBlobs: string[],
	localBlobStorage: string,
	onProgress?: (progress: BlobDownloadProgress) => void
): Promise<void> {
	const progress: Map<string, BlobDownloadProgress> = new Map();

	// Initialize progress tracking
	missingBlobs.forEach((digest) => {
		progress.set(digest, {
			digest,
			status: 'pending',
			bytesDownloaded: 0,
			totalBytes: 0
		});
	});

	// Download blobs in parallel (with concurrency limit)
	const concurrency = 3; // Download 3 blobs at a time
	const semaphore = new Semaphore(concurrency);

	const downloadPromises = missingBlobs.map(async (digest) => {
		await semaphore.acquire();

		try {
			// Update status
			progress.set(digest, {
				...progress.get(digest)!,
				status: 'downloading'
			});
			onProgress?.(progress.get(digest)!);

			// Derive local blob path
			const digestHash = digest.replace('sha256:', '');
			const localBlobPath = path.join(
				localBlobStorage,
				'blobs',
				'sha256',
				digestHash.slice(0, 2),
				digestHash.slice(2, 4),
				digestHash
			);

			// Download blob
			await downloadBlob(client, repositoryName, digest, localBlobPath);

			// Update status
			progress.set(digest, {
				...progress.get(digest)!,
				status: 'completed',
				bytesDownloaded: (await fs.promises.stat(localBlobPath)).size,
				totalBytes: (await fs.promises.stat(localBlobPath)).size
			});
			onProgress?.(progress.get(digest)!);
		} catch (error) {
			// Update status
			progress.set(digest, {
				...progress.get(digest)!,
				status: 'failed',
				error: error.message
			});
			onProgress?.(progress.get(digest)!);
			throw error;
		} finally {
			semaphore.release();
		}
	});

	await Promise.all(downloadPromises);
}
```

---

## 7. Storage Driver Implementations

### 7.1 Filesystem Driver

```go
// Filesystem driver implementation (simplified)
type filesystemDriver struct {
    rootDirectory string
}

func (d *filesystemDriver) Reader(ctx context.Context, path string, offset int64) (io.ReadCloser, error) {
    fullPath := filepath.Join(d.rootDirectory, path)

    file, err := os.Open(fullPath)
    if err != nil {
        return nil, err
    }

    // Seek to offset (for Range requests)
    if offset > 0 {
        _, err = file.Seek(offset, io.SeekStart)
        if err != nil {
            file.Close()
            return nil, err
        }
    }

    return file, nil
}

func (d *filesystemDriver) Stat(ctx context.Context, path string) (FileInfo, error) {
    fullPath := filepath.Join(d.rootDirectory, path)

    stat, err := os.Stat(fullPath)
    if err != nil {
        return nil, err
    }

    return &fileInfo{
        size: stat.Size(),
        modTime: stat.ModTime(),
    }, nil
}
```

### 7.2 S3 Driver

```go
// S3 driver implementation (simplified)
type s3Driver struct {
    bucket string
    s3Client *s3.S3
}

func (d *s3Driver) Reader(ctx context.Context, path string, offset int64) (io.ReadCloser, error) {
    // S3 key is the blob path
    key := path

    // Get object with Range request (if offset > 0)
    input := &s3.GetObjectInput{
        Bucket: aws.String(d.bucket),
        Key: aws.String(key),
    }

    if offset > 0 {
        // Range: bytes=offset-
        rangeHeader := fmt.Sprintf("bytes=%d-", offset)
        input.Range = aws.String(rangeHeader)
    }

    result, err := d.s3Client.GetObjectWithContext(ctx, input)
    if err != nil {
        return nil, err
    }

    return result.Body, nil
}

func (d *s3Driver) Stat(ctx context.Context, path string) (FileInfo, error) {
    key := path

    headInput := &s3.HeadObjectInput{
        Bucket: aws.String(d.bucket),
        Key: aws.String(key),
    }

    result, err := d.s3Client.HeadObjectWithContext(ctx, headInput)
    if err != nil {
        return nil, err
    }

    return &fileInfo{
        size: *result.ContentLength,
        modTime: *result.LastModified,
    }, nil
}
```

### 7.3 Presigned URL Pattern (S3)

For S3, Harbor can generate **presigned URLs** for direct client downloads:

```go
// Generate presigned URL for blob download
func (d *s3Driver) PresignedURL(ctx context.Context, path string, expiresIn time.Duration) (string, error) {
    key := path

    req, _ := d.s3Client.GetObjectRequest(&s3.GetObjectInput{
        Bucket: aws.String(d.bucket),
        Key: aws.String(key),
    })

    url, err := req.Presign(expiresIn)
    if err != nil {
        return "", err
    }

    return url, nil
}
```

**Client-side usage**:

```typescript
// Get presigned URL from Harbor API
const presignedUrl = await client.get(`/api/v2.0/blobs/url?digest=${digest}`);

// Download directly from S3 (bypasses Harbor)
const response = await fetch(presignedUrl);
const blob = await response.blob();
```

---

## 8. Complete Integration: Pull Changes â†’ Download Blobs

### 8.1 Complete Flow

```typescript
async function pullChangesAndDownloadBlobs(
	client: SyncClient,
	workspaceId: string,
	fromVersion: number,
	localBlobStorage: string,
	db: Database
): Promise<void> {
	// Step 1: Pull changes from server
	const response = await client.pull({
		workspace_id: workspaceId,
		from_version: fromVersion
	});

	// Step 2: Parse manifests and extract blob digests
	const allBlobDigests: Set<string> = new Set();

	for (const change of response.changes) {
		if (change.action === 'create' || change.action === 'update') {
			const manifest = JSON.parse(change.data.manifest || '{}');
			const blobDigests = extractBlobDigests(manifest);
			blobDigests.forEach((digest) => allBlobDigests.add(digest));
		}
	}

	// Step 3: Check which blobs are missing locally
	const missingBlobs = await checkLocalBlobs(db, Array.from(allBlobDigests));

	// Also check server-provided missing_blobs list
	if (response.missing_blobs) {
		response.missing_blobs.forEach((digest) => {
			if (!allBlobDigests.has(digest)) {
				missingBlobs.push(digest);
			}
		});
	}

	// Step 4: Download missing blobs
	if (missingBlobs.length > 0) {
		console.log(`Downloading ${missingBlobs.length} missing blobs...`);

		await downloadBlobs(
			client,
			workspaceId, // repository name
			missingBlobs,
			localBlobStorage,
			(progress) => {
				console.log(
					`Blob ${progress.digest}: ${progress.status} (${progress.bytesDownloaded}/${progress.totalBytes} bytes)`
				);
			}
		);

		// Step 5: Update blob registry
		for (const digest of missingBlobs) {
			const digestHash = digest.replace('sha256:', '');
			const localBlobPath = path.join(
				localBlobStorage,
				'blobs',
				'sha256',
				digestHash.slice(0, 2),
				digestHash.slice(2, 4),
				digestHash
			);

			const stats = await fs.promises.stat(localBlobPath);

			await db.run(
				`INSERT INTO blob_registry (digest, size, path, created_at)
         VALUES (?, ?, ?, ?)`,
				[digest, stats.size, localBlobPath, new Date().toISOString()]
			);
		}
	}

	// Step 6: Apply changes to local SQLite (link blobs to artifacts)
	await applyServerChanges(db, response.changes, response.server_version, workspaceId);
}
```

---

## 9. Design Patterns for DataForge

### 9.1 Content-Addressed Blob Storage

**Harbor Pattern**:

- Blobs stored by SHA-256 digest: `blobs/sha256/{first2}/{next2}/{full_digest}`.
- Immutable: same digest = same content (deduplication).
- Metadata in PostgreSQL tracks blob references.

**DataForge Application**:

- Store Parquet files by SHA-256 hash: `blobs/{hash[0:2]}/{hash[2:4]}/{hash}.parquet`.
- Multiple curves can reference the same Parquet file (if data is identical).
- SQLite/PostgreSQL tracks which curves reference which blob hashes.

### 9.2 Missing Blob Detection

**Harbor Pattern**:

- Server returns `missing_blobs` list in pull response.
- Client also checks local storage before downloading.

**DataForge Application**:

- Server returns `missing_blobs` list in sync pull response.
- Client checks local `blob_registry` table before downloading.
- Deduplication: skip download if blob already exists locally.

### 9.3 Blob Download with Verification

**Harbor Pattern**:

- Compute SHA-256 digest while downloading.
- Verify digest matches expected digest before storing.
- Atomic write (write to temp, then rename).

**DataForge Application**:

- Compute SHA-256 hash while downloading Parquet file.
- Verify hash matches expected hash before storing.
- Atomic write to prevent corruption.

### 9.4 Presigned URLs for Direct Downloads

**Harbor Pattern**:

- For S3, generate presigned URLs for direct client downloads.
- Bypasses Harbor server (reduces load, faster downloads).

**DataForge Application**:

- For S3/MinIO, generate presigned URLs for Parquet file downloads.
- Client downloads directly from S3 (bypasses sync server).
- Sync server only provides presigned URLs, not blob data.

---

## 10. Summary

### âœ… Key Patterns

1. **Manifest â†’ Blob References**: Parse manifest to extract blob digests.
2. **Missing Blob Detection**: Check local storage before downloading.
3. **Content-Addressed Storage**: Store blobs by digest (deduplication).
4. **Blob Verification**: Compute and verify SHA-256 digest during download.
5. **Atomic Writes**: Write to temp file, then rename (prevents corruption).
6. **Presigned URLs**: Direct S3 downloads (bypasses server).

### ğŸ“‹ Best Practices

1. **Check local storage first** (deduplication).
2. **Verify blob integrity** (SHA-256 digest).
3. **Use atomic writes** (temp file â†’ rename).
4. **Support Range requests** (resume downloads).
5. **Download in parallel** (with concurrency limit).
6. **Track download progress** (for UI feedback).

This architecture provides a robust foundation for downloading blobs referenced by pulled changes while maintaining data integrity and supporting efficient deduplication.

